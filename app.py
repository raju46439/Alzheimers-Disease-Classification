# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yPcNqmLTAFLSNqe21twWReG41uEDawzp
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# ------------------ PAGE CONFIG ------------------
st.set_page_config(page_title="Alzheimer's Prediction System", layout="wide")
st.title("üß† Alzheimer's Disease Prediction System")

# ------------------ DATASET UPLOAD ------------------
st.sidebar.header("üìÇ Upload Dataset")
uploaded_data = st.sidebar.file_uploader("Upload CSV File", type=["csv"])

if uploaded_data is None:
    st.warning("‚ö† Please upload a dataset to continue.")
    st.stop()

df = pd.read_csv(uploaded_data)

# clean dataset (matches notebook preprocessing)
df = df.drop(["PatientID", "DoctorInCharge"], axis=1, errors="ignore")

# ------------------ DATASET SUMMARY ------------------
st.subheader("üìä Dataset Summary")

c1, c2, c3 = st.columns(3)
with c1: st.metric("Total Records", df.shape[0])
with c2: st.metric("Total Features", df.shape[1] - 1)
with c3: st.metric("Target Classes", df["Diagnosis"].nunique())

st.dataframe(df.head())
st.subheader("üìà Statistical Summary")
st.dataframe(df.describe())

# ------------------ DATA SPLITTING ------------------
x = df.drop("Diagnosis", axis=1)
y = df["Diagnosis"]

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.2, random_state=42
)

# ------------------ MODEL TRAINING ------------------
lr = LogisticRegression(max_iter=1000)
rf = RandomForestClassifier(random_state=42)

models = {
    "Logistic Regression": lr,
    "Random Forest": rf
}

accuracy_results = {}

for name, model in models.items():
    model.fit(x_train, y_train)
    preds = model.predict(x_test)
    accuracy_results[name] = accuracy_score(y_test, preds)

best_model_name = max(accuracy_results, key=accuracy_results.get)
best_model = models[best_model_name]

# ------------------ SIDEBAR MENU ------------------
st.sidebar.title("üìå Dashboard Menu")
menu = st.sidebar.radio(
    "Select Option:",
    ["Home", "Dataset Analysis", "Model Comparison", "Single Prediction", "Bulk Prediction"]
)

# ------------------ HOME ------------------
if menu == "Home":
    st.subheader("üè† System Overview")
    st.write("""
    This system predicts the risk of Alzheimer's Disease using Machine Learning.

    ‚úî Automatic model training
    ‚úî Real-time prediction
    ‚úî Visualization and EDA
    ‚úî Upload your own dataset
    ‚úî Bulk prediction support
    """)
    st.success(f"üèÜ Best Model: {best_model_name}")

# ------------------ DATASET ANALYSIS ------------------
elif menu == "Dataset Analysis":
    st.subheader("üìä Dataset Analysis & Visualization")

    # Diagnosis Distribution
    st.write("### Diagnosis Distribution")
    fig1, ax1 = plt.subplots(figsize=(6, 3))
    sns.countplot(x=df["Diagnosis"], palette="Set2", ax=ax1)
    st.pyplot(fig1)

    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()


# ------------------ MODEL COMPARISON ------------------
elif menu == "Model Comparison":
    st.subheader("üìà Model Accuracy Comparison")

    acc_df = pd.DataFrame(accuracy_results.items(), columns=["Model", "Accuracy"])
    acc_df = acc_df.sort_values("Accuracy", ascending=False)
    st.dataframe(acc_df)

    fig4, ax4 = plt.subplots(figsize=(6, 3))
    sns.barplot(x="Model", y="Accuracy", data=acc_df, palette="Set1", ax=ax4)
    ax4.set_ylim(0, 1)
    st.pyplot(fig4)

    st.success(f"üèÜ Automatically selected: {best_model_name}")

# ------------------ SINGLE PATIENT PREDICTION ------------------
elif menu == "Single Prediction":
    st.subheader("üîç Single Patient Prediction")

    st.info("Enter patient details. Defaults are dataset means.")

    input_list = []
    default_vals = x.mean()

    for col in x.columns:
        val = st.number_input(col, value=float(default_vals[col]))
        input_list.append(val)

    input_array = np.array(input_list).reshape(1, -1)

    if st.button("Predict"):
        result = best_model.predict(input_array)[0]
        if result == 1:
            st.error("‚ö† High Risk of Alzheimer's Detected")
        else:
            st.success("‚úÖ Low Risk of Alzheimer's")

# ------------------ BULK PREDICTION ------------------
elif menu == "Bulk Prediction":
    st.subheader("üìÇ Bulk Prediction")

    csv_file = st.file_uploader("Upload CSV for Prediction", type=["csv"])

    if csv_file is not None:
        new_df = pd.read_csv(csv_file)

        # clean columns
        new_df = new_df.drop(["PatientID", "DoctorInCharge", "Diagnosis"], axis=1, errors="ignore")

        # align to training cols
        missing_cols = set(x.columns) - set(new_df.columns)
        for col in missing_cols:
            new_df[col] = np.nan  # will be handled manually

        new_df = new_df[x.columns]

        try:
            preds = best_model.predict(new_df)
            new_df["Prediction"] = preds

            st.dataframe(new_df)

            csv = new_df.to_csv(index=False).encode("utf-8")
            st.download_button(
                "‚¨á Download Predictions",
                csv,
                "alzheimers_predictions.csv",
                "text/csv"
            )
        except Exception as e:
            st.error(f"Prediction Error: {e}")